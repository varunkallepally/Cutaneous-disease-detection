{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huqLJhYRvYsx"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow_federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnAqBpQb0jNM",
        "outputId": "65eb11a8-6d0d-4169-ca87-c2f4efe99d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import layers, regularizers, optimizers, callbacks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "icHwlCj0I1K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsYO3dEN1cwx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "def download_kaggle_dataset(dataset_name):\n",
        "    # Step 1: Upload Kaggle API key file (kaggle.json)\n",
        "    files.upload()\n",
        "\n",
        "    # Step 2: Install Kaggle API\n",
        "    !pip install -q kaggle\n",
        "\n",
        "    # Step 3: Move kaggle.json to the appropriate directory\n",
        "    !mkdir ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/\n",
        "\n",
        "    # Step 4: Set permissions for kaggle.json\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "    # Step 5: Download dataset using Kaggle API\n",
        "    !kaggle datasets download -d {dataset_name}\n",
        "\n",
        "    # Step 6: Unzip downloaded dataset\n",
        "    zip_file = f\"{dataset_name.split('/')[-1]}.zip\"\n",
        "    !unzip -q {zip_file}\n",
        "\n",
        "    # Step 7: Remove the zip file\n",
        "    os.remove(zip_file)\n",
        "\n",
        "# Example usage:\n",
        "dataset_name = \"kmader/skin-cancer-mnist-ham10000\"\n",
        "download_kaggle_dataset(dataset_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Check if GPU is available\n",
        "device = '/GPU:0' if tf.config.experimental.list_physical_devices('GPU') else '/CPU:0'\n",
        "\n",
        "# Define paths\n",
        "HAM_PATH_PART1 = \"/content/drive/MyDrive/archive/HAM10000_images_part_1\"\n",
        "HAM_PATH_PART2 = \"/content/drive/MyDrive/archive/HAM10000_images_part_2\"\n",
        "METADATA_PATH = \"/content/drive/MyDrive/archive/HAM10000_metadata.csv\"\n",
        "\n",
        "def load_data_ham(path, metadata_path):\n",
        "    print(\"Loading data from:\", path)\n",
        "    data = []\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    for img_file in os.listdir(path):\n",
        "        img_id = img_file.split('.')[0]\n",
        "        metadata_row = metadata[metadata['image_id'] == img_id]\n",
        "        if not metadata_row.empty:\n",
        "            lesion_type = metadata_row.iloc[0]['dx']\n",
        "            img_path = os.path.join(path, img_file)\n",
        "            img_resize = process_image(img_path)\n",
        "            data.append([img_resize, lesion_type])\n",
        "    return data\n",
        "\n",
        "def process_image(img_path, target_size=(392, 384)):\n",
        "    img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Resize image to target size\n",
        "    img_resize = cv2.resize(img_array, target_size)\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    img_normalize = img_resize.astype(np.float32) / 255.0\n",
        "\n",
        "    return img_normalize\n",
        "\n",
        "# Load data for HAM dataset\n",
        "with tf.device(device):\n",
        "    ham_data_part1 = load_data_ham(HAM_PATH_PART1, METADATA_PATH)\n",
        "    ham_data_part2 = load_data_ham(HAM_PATH_PART2, METADATA_PATH)\n",
        "\n",
        "# Concatenate HAM datasets into a single list\n",
        "all_ham_data = ham_data_part1 + ham_data_part2\n",
        "\n",
        "# Convert the list of lists to a DataFrame\n",
        "column_names = ['image_data', 'skin_disease']\n",
        "ham_df = pd.DataFrame(all_ham_data, columns=column_names)\n",
        "\n",
        "# Print the structure of the merged HAM dataset\n",
        "print(\"Structure of the merged HAM dataset:\")\n",
        "print(ham_df.head())\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'skin_disease' column\n",
        "ham_df['skin_disease'] = label_encoder.fit_transform(ham_df['skin_disease'])\n",
        "\n",
        "# Print the encoded DataFrame\n",
        "print(ham_df.head())\n",
        "df=pd.DataFrame(ham_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSesAlUhGa7Y",
        "outputId": "66bb20ca-2f12-49c2-e9ea-4e46a0d56524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from: /content/drive/MyDrive/archive/HAM10000_images_part_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfbkjCu99kZk"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "num_client = 10\n",
        "\n",
        "df[\"client\"] = [\"client_{}\".format(random.randint(1, num_client)) for _ in range(df.shape[0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bV_rrtA9tl0"
      },
      "outputs": [],
      "source": [
        "client_id_colname = 'client'\n",
        "\n",
        "client_ids = df[client_id_colname].unique()\n",
        "\n",
        "train_client_ids = pd.DataFrame(client_ids).sample(frac=0.8).values.ravel().tolist()\n",
        "test_client_ids = [x for x in client_ids if x not in train_client_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TD5je4xMttDQ"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfN-N2yGuET_"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNQOl-nluRUW",
        "outputId": "c4a383fe-66ea-44c1-86b2-af051867c4d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['client_2',\n",
              " 'client_4',\n",
              " 'client_1',\n",
              " 'client_6',\n",
              " 'client_8',\n",
              " 'client_7',\n",
              " 'client_9',\n",
              " 'client_5']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_client_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOu217ns6TVS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gGE61tA5qQD"
      },
      "outputs": [],
      "source": [
        "features =\"image_data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD8S1cmyuTxJ"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "NUM_EPOCHS = 1\n",
        "SHUFFLE_BUFFER = 100\n",
        "\n",
        "def create_tf_dataset_for_client_fn(client_id):\n",
        "    client_data = dataframe[dataframe[client_id_colname] == client_id]\n",
        "    client_data_dict = OrderedDict()\n",
        "    client_data_dict[\"image_data\"] = np.array(client_data['image_data'].values.tolist(), dtype=\"float32\")\n",
        "    client_data_dict[\"skin_disease\"] = np.array(client_data['skin_disease'].values.tolist(), dtype=\"int32\")\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(client_data_dict)\n",
        "    dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(1).repeat(NUM_EPOCHS)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5EzgzPg5B12"
      },
      "outputs": [],
      "source": [
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fctdicequgU0"
      },
      "outputs": [],
      "source": [
        "dataframe = train_df\n",
        "train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
        "    client_ids=train_client_ids,\n",
        "    serializable_dataset_fn=create_tf_dataset_for_client_fn)\n",
        "\n",
        "dataframe = test_df\n",
        "test_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
        "    client_ids=test_client_ids,\n",
        "    serializable_dataset_fn=create_tf_dataset_for_client_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAL3CJfsuojI",
        "outputId": "0278fd0d-6773-4a3e-ffe8-bdd453a60271"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('image_data',\n",
              "              TensorSpec(shape=(None, 3, 784), dtype=tf.float32, name=None)),\n",
              "             ('skin_disease_encoded',\n",
              "              TensorSpec(shape=(None,), dtype=tf.int32, name=None))])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.element_type_structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZFJ8kXzurqn"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "NUM_EPOCHS = 1\n",
        "BATCH_SIZE = 10\n",
        "SHUFFLE_BUFFER = 100\n",
        "PREFETCH_BUFFER = 10\n",
        "\n",
        "def preprocess(dataset):\n",
        "    def batch_format_fn(element):\n",
        "        return collections.OrderedDict(x=tf.reshape(element['image_data'], [-1,224,224,3]),\n",
        "                                       y=tf.reshape(element['skin_disease'], [-1, 1]))\n",
        "\n",
        "    return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(\n",
        "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66xawggluxcH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def make_federated_data(client_data, client_ids):\n",
        "    return [preprocess(client_data.create_tf_dataset_for_client(x)) for x in tqdm(client_ids)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty_EXCnDu2W-",
        "outputId": "e66c404d-0f2b-4666-bff2-feb8ad6fb83b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▎        | 1/8 [00:00<00:02,  2.93it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:02,  2.97it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:01,  3.11it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:01<00:01,  3.19it/s]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:01<00:00,  3.22it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:01<00:00,  3.30it/s]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:02<00:00,  3.36it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:02<00:00,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of client datasets: 8\n",
            "First dataset: <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "NUM_CLIENTS = len(np.unique(train_df[client_id_colname]))\n",
        "\n",
        "sample_clients = train_data.client_ids[0:NUM_CLIENTS]\n",
        "\n",
        "federated_train_data = make_federated_data(train_data, sample_clients)\n",
        "\n",
        "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
        "print('First dataset: {d}'.format(d=federated_train_data[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poUGVdJau5Oo"
      },
      "outputs": [],
      "source": [
        "def create_keras_model(input_shape=(224, 224, 3), num_classes=7):\n",
        "    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
        "    x = base_model(x, training=False)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOOdP_bd_1TW",
        "outputId": "259f359e-8052-417d-abd1-20cbd9795ea0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "example_dataset = train_data.create_tf_dataset_for_client(train_data.client_ids[0])\n",
        "\n",
        "example_element = next(iter(example_dataset))\n",
        "\n",
        "example_element['skin_disease'].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO0SsKGp_6SX"
      },
      "outputs": [],
      "source": [
        "preprocessed_example_dataset = preprocess(example_dataset)\n",
        "\n",
        "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
        "                                     next(iter(preprocessed_example_dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQIz3Y5hCBis",
        "outputId": "12127203-6508-4863-a1f6-fddc0f26847e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('x',\n",
              "              TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None)),\n",
              "             ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "preprocessed_example_dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfGtbNPNu-Sg"
      },
      "outputs": [],
      "source": [
        "from keras.metrics import Recall, Precision\n",
        "\n",
        "def model_fn():\n",
        "    keras_model = create_keras_model()\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model,\n",
        "        input_spec=preprocessed_example_dataset.element_spec,\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JlI5MCBvDBs"
      },
      "outputs": [],
      "source": [
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.001))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "yvncHzkpSvvZ",
        "outputId": "6bb52b45-7566-445a-83d8-c8e8728e2ed7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'( -> <global_model_weights=<trainable=<float32[3,3,3,32],float32[32],float32[3,3,32,64],float32[64],float32[3,3,64,64],float32[64],float32[576,64],float32[64],float32[64,9],float32[9]>,non_trainable=<>>,distributor=<>,client_work=<>,aggregator=<value_sum_process=<>,weight_sum_process=<>>,finalizer=<learning_rate=float32>>@SERVER)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "str(iterative_process.initialize.type_signature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McSAcknsvGdJ"
      },
      "outputs": [],
      "source": [
        "state = iterative_process.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "FCF_LfhzvJTe",
        "outputId": "6b1e650a-cbc8-4c93-dd2f-3f544ab1a1b3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'state' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-39d62fa827ea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterative_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfederated_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'round  1, metrics={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
          ]
        }
      ],
      "source": [
        "state, metrics = iterative_process.next(state, federated_train_data)\n",
        "print('round  1, metrics={}'.format(metrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahB5G3FeuT4G"
      },
      "outputs": [],
      "source": [
        "NUM_ROUNDS = 11\n",
        "for round_num in range(2, NUM_ROUNDS):\n",
        "  result = iterative_process.next(state, federated_train_data)\n",
        "  train_state = result.state\n",
        "  train_metrics = result.metrics\n",
        "  print('round {:2d}, metrics={}'.format(round_num, train_metrics))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_process = tff.learning.algorithms.build_fed_eval(model_fn)"
      ],
      "metadata": {
        "id": "eV0o9seMtVIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_state = evaluation_process.initialize()\n",
        "model_weights = iterative_process.get_model_weights(train_state)\n",
        "evaluation_state = evaluation_process.set_model_weights(evaluation_state, model_weights)"
      ],
      "metadata": {
        "id": "TJIvmqGNtX0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "federated_test_data = make_federated_data(test_data, sample_clients)\n",
        "\n",
        "len(federated_test_data), federated_test_data[0]"
      ],
      "metadata": {
        "id": "rE6m7U6Htw-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_output = evaluation_process.next(evaluation_state, federated_test_data)"
      ],
      "metadata": {
        "id": "g0mEZ-39t8nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(evaluation_output.metrics)"
      ],
      "metadata": {
        "id": "aBDzbDPFuABb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}