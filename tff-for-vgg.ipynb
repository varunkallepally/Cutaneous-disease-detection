{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install tensorflow_federated","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-18T14:50:45.378887Z","iopub.execute_input":"2024-04-18T14:50:45.379651Z","iopub.status.idle":"2024-04-18T14:53:03.333037Z","shell.execute_reply.started":"2024-04-18T14:50:45.379616Z","shell.execute_reply":"2024-04-18T14:53:03.331919Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow_federated\n  Downloading tensorflow_federated-0.75.0-py3-none-manylinux_2_31_x86_64.whl.metadata (4.0 kB)\nRequirement already satisfied: absl-py==1.*,>=1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_federated) (1.4.0)\nRequirement already satisfied: attrs~=23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow_federated) (23.2.0)\nCollecting cachetools~=5.3 (from tensorflow_federated)\n  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: dm-tree==0.1.8 in /opt/conda/lib/python3.10/site-packages (from tensorflow_federated) (0.1.8)\nCollecting dp-accounting==0.4.3 (from tensorflow_federated)\n  Downloading dp_accounting-0.4.3-py3-none-any.whl.metadata (1.8 kB)\nCollecting farmhashpy==0.4.0 (from tensorflow_federated)\n  Downloading farmhashpy-0.4.0.tar.gz (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting google-vizier==0.1.11 (from tensorflow_federated)\n  Downloading google_vizier-0.1.11-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: grpcio~=1.46 in /opt/conda/lib/python3.10/site-packages (from tensorflow_federated) (1.51.1)\nCollecting jaxlib==0.4.14 (from tensorflow_federated)\n  Downloading jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.0 kB)\nCollecting jax==0.4.14 (from tensorflow_federated)\n  Downloading jax-0.4.14.tar.gz (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy~=1.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow_federated) (1.26.4)\nCollecting portpicker~=1.6 (from tensorflow_federated)\n  Downloading portpicker-1.6.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting scipy~=1.9.3 (from tensorflow_federated)\n  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting semantic-version~=2.6 (from tensorflow_federated)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting tensorflow-compression==2.14.*,>=2.14.0 (from tensorflow_federated)\n  Downloading tensorflow_compression-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nCollecting tensorflow-model-optimization==0.7.5 (from tensorflow_federated)\n  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\nCollecting tensorflow-privacy==0.9.0 (from tensorflow_federated)\n  Downloading tensorflow_privacy-0.9.0-py3-none-any.whl.metadata (763 bytes)\nCollecting tensorflow==2.14.*,>=2.14.0 (from tensorflow_federated)\n  Downloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: tqdm~=4.64 in /opt/conda/lib/python3.10/site-packages (from tensorflow_federated) (4.66.1)\nCollecting typing-extensions==4.5.*,>=4.5.0 (from tensorflow_federated)\n  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\nCollecting googleapis-common-protos==1.61.0 (from tensorflow_federated)\n  Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: mpmath~=1.2 in /opt/conda/lib/python3.10/site-packages (from dp-accounting==0.4.3->tensorflow_federated) (1.3.0)\nCollecting attrs~=23.1 (from tensorflow_federated)\n  Downloading attrs-23.1.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: protobuf>=3.6 in /opt/conda/lib/python3.10/site-packages (from google-vizier==0.1.11->tensorflow_federated) (3.20.3)\nCollecting grpcio-tools>=1.35.0 (from google-vizier==0.1.11->tensorflow_federated)\n  Downloading grpcio_tools-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\nCollecting sqlalchemy<=1.4.20,>=1.4 (from google-vizier==0.1.11->tensorflow_federated)\n  Downloading SQLAlchemy-1.4.20.tar.gz (7.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.14->tensorflow_federated) (0.2.0)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax==0.4.14->tensorflow_federated) (3.3.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (16.0.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (21.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.4.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.35.0)\nCollecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\nCollecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting keras<2.15,>=2.14.0 (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\nINFO: pip is looking at multiple versions of tensorflow-compression to determine which version is compatible with other requirements. This could take a while.\nCollecting tensorflow-compression==2.14.*,>=2.14.0 (from tensorflow_federated)\n  Downloading tensorflow_compression-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\nRequirement already satisfied: tensorflow-probability~=0.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow-compression==2.14.*,>=2.14.0->tensorflow_federated) (0.23.0)\nCollecting packaging (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n  Downloading packaging-22.0-py3-none-any.whl.metadata (3.1 kB)\nRequirement already satisfied: scikit-learn==1.*,>=1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-privacy==0.9.0->tensorflow_federated) (1.2.2)\nCollecting tensorflow-probability~=0.15 (from tensorflow-compression==2.14.*,>=2.14.0->tensorflow_federated)\n  Downloading tensorflow_probability-0.22.1-py2.py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow_federated) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow_federated) (3.2.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker~=1.6->tensorflow_federated) (5.9.3)\nCollecting numpy~=1.25 (from tensorflow_federated)\n  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.42.0)\nCollecting protobuf>=3.6 (from google-vizier==0.1.11->tensorflow_federated)\n  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting grpcio~=1.46 (from tensorflow_federated)\n  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<=1.4.20,>=1.4->google-vizier==0.1.11->tensorflow_federated) (3.0.3)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.26.1)\nCollecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.0.1)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability~=0.15->tensorflow-compression==2.14.*,>=2.14.0->tensorflow_federated) (5.1.1)\nRequirement already satisfied: cloudpickle>=1.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability~=0.15->tensorflow-compression==2.14.*,>=2.14.0->tensorflow_federated) (2.2.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.2.2)\nDownloading tensorflow_federated-0.75.0-py3-none-manylinux_2_31_x86_64.whl (70.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dp_accounting-0.4.3-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_vizier-0.1.11-py3-none-any.whl (721 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.6/721.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading attrs-23.1.0-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl (230 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl (73.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_compression-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (257 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.7/257.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_privacy-0.9.0-py3-none-any.whl (323 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\nDownloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\nDownloading portpicker-1.6.0-py3-none-any.whl (16 kB)\nDownloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading grpcio_tools-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-22.0-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_probability-0.22.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\nBuilding wheels for collected packages: farmhashpy, jax, sqlalchemy\n  Building wheel for farmhashpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for farmhashpy: filename=farmhashpy-0.4.0-cp310-cp310-linux_x86_64.whl size=12965 sha256=48cca532ffe4751b8afd0ef80bd88fe061960ec9e94e97bcac82e2b7fda3a9ba\n  Stored in directory: /root/.cache/pip/wheels/14/0e/36/b61b3f47ae366b7d5dd2b746326d17234269dbc745ad554857\n  Building wheel for jax (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jax: filename=jax-0.4.14-py3-none-any.whl size=1535361 sha256=2b6b19e8f498ac3bcb5b654e6307e7f6a6c0c42f6e6e2dfadbe1136be74c3249\n  Stored in directory: /root/.cache/pip/wheels/85/52/e7/dfa571c9f9b879e3facaa1584f52be04c4c3d1e14054ef40ab\n  Building wheel for sqlalchemy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sqlalchemy: filename=SQLAlchemy-1.4.20-cp310-cp310-linux_x86_64.whl size=1490638 sha256=04f678e2c733c8007b772a7b22bc1006e4c388f83836c1693cdaf47d28858b50\n  Stored in directory: /root/.cache/pip/wheels/c4/42/20/a958989c470cc1a6fe1d1279b0193f0e508161327fc3d951d9\nSuccessfully built farmhashpy jax sqlalchemy\nInstalling collected packages: typing-extensions, tensorflow-estimator, sqlalchemy, semantic-version, protobuf, portpicker, packaging, numpy, keras, grpcio, farmhashpy, cachetools, attrs, tensorflow-probability, tensorflow-model-optimization, scipy, grpcio-tools, googleapis-common-protos, jaxlib, jax, google-vizier, google-auth-oauthlib, dp-accounting, tensorboard, tensorflow, tensorflow-privacy, tensorflow-compression, tensorflow_federated\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.9.0\n    Uninstalling typing_extensions-4.9.0:\n      Successfully uninstalled typing_extensions-4.9.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.15.0\n    Uninstalling tensorflow-estimator-2.15.0:\n      Successfully uninstalled tensorflow-estimator-2.15.0\n  Attempting uninstall: sqlalchemy\n    Found existing installation: SQLAlchemy 2.0.25\n    Uninstalling SQLAlchemy-2.0.25:\n      Successfully uninstalled SQLAlchemy-2.0.25\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: keras\n    Found existing installation: keras 3.0.5\n    Uninstalling keras-3.0.5:\n      Successfully uninstalled keras-3.0.5\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.51.1\n    Uninstalling grpcio-1.51.1:\n      Successfully uninstalled grpcio-1.51.1\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 4.2.4\n    Uninstalling cachetools-4.2.4:\n      Successfully uninstalled cachetools-4.2.4\n  Attempting uninstall: attrs\n    Found existing installation: attrs 23.2.0\n    Uninstalling attrs-23.2.0:\n      Successfully uninstalled attrs-23.2.0\n  Attempting uninstall: tensorflow-probability\n    Found existing installation: tensorflow-probability 0.23.0\n    Uninstalling tensorflow-probability-0.23.0:\n      Successfully uninstalled tensorflow-probability-0.23.0\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.11.4\n    Uninstalling scipy-1.11.4:\n      Successfully uninstalled scipy-1.11.4\n  Attempting uninstall: googleapis-common-protos\n    Found existing installation: googleapis-common-protos 1.62.0\n    Uninstalling googleapis-common-protos-1.62.0:\n      Successfully uninstalled googleapis-common-protos-1.62.0\n  Attempting uninstall: jaxlib\n    Found existing installation: jaxlib 0.4.23.dev20240116\n    Uninstalling jaxlib-0.4.23.dev20240116:\n      Successfully uninstalled jaxlib-0.4.23.dev20240116\n  Attempting uninstall: jax\n    Found existing installation: jax 0.4.23\n    Uninstalling jax-0.4.23:\n      Successfully uninstalled jax-0.4.23\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.0\n    Uninstalling google-auth-oauthlib-1.2.0:\n      Successfully uninstalled google-auth-oauthlib-1.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.2 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nalbumentations 1.4.0 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.25.2 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nchex 0.1.85 requires jax>=0.4.16, but you have jax 0.4.14 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\nfastapi 0.108.0 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\nfeaturetools 1.30.0 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\nflax 0.8.2 requires jax>=0.4.19, but you have jax 0.4.14 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2024.3.0 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 22.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.3 which is incompatible.\ngoogle-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\ngoogle-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.3 which is incompatible.\nipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.20 which is incompatible.\njupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkaggle-environments 1.14.3 requires scipy>=1.11.2, but you have scipy 1.9.3 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\nkfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npydantic 2.5.3 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\npydantic-core 2.14.6 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\npylibraft 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\npytoolconfig 1.3.1 requires packaging>=23.2, but you have packaging 22.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\nrmm 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.14.1 which is incompatible.\ntensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.14.1 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\ntensorstore 0.1.56 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\ntf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.14.1 which is incompatible.\ntypeguard 4.1.5 requires typing-extensions>=4.7.0; python_version < \"3.12\", but you have typing-extensions 4.5.0 which is incompatible.\nwoodwork 0.29.0 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed attrs-23.1.0 cachetools-5.3.2 dp-accounting-0.4.3 farmhashpy-0.4.0 google-auth-oauthlib-1.0.0 google-vizier-0.1.11 googleapis-common-protos-1.61.0 grpcio-1.60.0 grpcio-tools-1.62.1 jax-0.4.14 jaxlib-0.4.14 keras-2.14.0 numpy-1.25.2 packaging-22.0 portpicker-1.6.0 protobuf-4.21.12 scipy-1.12.0 semantic-version-2.10.0 sqlalchemy-1.4.20 tensorboard-2.14.1 tensorflow-2.14.1 tensorflow-compression-2.14.0 tensorflow-estimator-2.14.0 tensorflow-model-optimization-0.7.5 tensorflow-privacy-0.9.0 tensorflow-probability-0.22.1 tensorflow_federated-0.75.0 typing-extensions-4.5.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport itertools\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical, plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import layers, regularizers, optimizers, callbacks\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:53:03.336860Z","iopub.execute_input":"2024-04-18T14:53:03.337141Z","iopub.status.idle":"2024-04-18T14:53:10.208919Z","shell.execute_reply.started":"2024-04-18T14:53:03.337115Z","shell.execute_reply":"2024-04-18T14:53:10.208025Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n2024-04-18 14:53:05.538857: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-18 14:53:05.538935: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-18 14:53:05.538995: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\n\n# Check if GPU is available\ndevice = '/GPU:0' if tf.config.experimental.list_physical_devices('GPU') else '/CPU:0'\n# Define paths\nHAM_PATH_PART1 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1\"\nHAM_PATH_PART2 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2\"\nMETADATA_PATH = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\"\n\ndef load_data_ham(path, metadata_path):\n    print(\"Loading data from:\", path)\n    data = []\n    metadata = pd.read_csv(metadata_path)\n    for img_file in os.listdir(path):\n        img_id = img_file.split('.')[0]\n        metadata_row = metadata[metadata['image_id'] == img_id]\n        if not metadata_row.empty:\n            lesion_type = metadata_row.iloc[0]['dx']\n            img_path = os.path.join(path, img_file)\n            img_resize = process_image(img_path)\n            data.append([img_resize, lesion_type])\n    return data\n\ndef process_image(img_path, target_size=(64, 48)):\n    img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    img_resize = cv2.resize(img_array, target_size)\n    img_normalize = img_resize.astype(np.float32) / 255.0\n    return img_normalize\n\nwith tf.device(device):\n    ham_data_part1 = load_data_ham(HAM_PATH_PART1, METADATA_PATH)\n    ham_data_part2 = load_data_ham(HAM_PATH_PART2, METADATA_PATH)\nall_ham_data = ham_data_part1 + ham_data_part2\ncolumn_names = ['image_data', 'skin_disease']\nham_df = pd.DataFrame(all_ham_data, columns=column_names)\nprint(\"Structure of the merged HAM dataset:\")\nprint(ham_df.head())\nlabel_encoder = LabelEncoder()\nham_df['skin_disease'] = label_encoder.fit_transform(ham_df['skin_disease'])\nprint(ham_df.head())\ndf=pd.DataFrame(ham_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:53:10.209895Z","iopub.execute_input":"2024-04-18T14:53:10.210411Z","iopub.status.idle":"2024-04-18T14:56:09.865002Z","shell.execute_reply.started":"2024-04-18T14:53:10.210386Z","shell.execute_reply":"2024-04-18T14:56:09.864028Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Loading data from: /kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1\nLoading data from: /kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2\nStructure of the merged HAM dataset:\n                                          image_data skin_disease\n0  [[0.68235296, 0.6666667, 0.6784314, 0.6509804,...           nv\n1  [[0.5568628, 0.5803922, 0.5764706, 0.58431375,...           nv\n2  [[0.6666667, 0.6431373, 0.67058825, 0.7058824,...           nv\n3  [[0.54509807, 0.53333336, 0.5254902, 0.4862745...          bkl\n4  [[0.5764706, 0.5686275, 0.5647059, 0.6039216, ...          bkl\n                                          image_data  skin_disease\n0  [[0.68235296, 0.6666667, 0.6784314, 0.6509804,...             5\n1  [[0.5568628, 0.5803922, 0.5764706, 0.58431375,...             5\n2  [[0.6666667, 0.6431373, 0.67058825, 0.7058824,...             5\n3  [[0.54509807, 0.53333336, 0.5254902, 0.4862745...             2\n4  [[0.5764706, 0.5686275, 0.5647059, 0.6039216, ...             2\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\n\nnum_client = 10\n\ndf[\"client\"] = [\"client_{}\".format(random.randint(1, num_client)) for _ in range(df.shape[0])]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:09.866301Z","iopub.execute_input":"2024-04-18T14:56:09.867079Z","iopub.status.idle":"2024-04-18T14:56:09.893107Z","shell.execute_reply.started":"2024-04-18T14:56:09.867041Z","shell.execute_reply":"2024-04-18T14:56:09.892220Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"client_id_colname = 'client'\n\nclient_ids = df[client_id_colname].unique()\n\ntrain_client_ids = pd.DataFrame(client_ids).sample(frac=0.8).values.ravel().tolist()\ntest_client_ids = [x for x in client_ids if x not in train_client_ids]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:09.895595Z","iopub.execute_input":"2024-04-18T14:56:09.895886Z","iopub.status.idle":"2024-04-18T14:56:09.910526Z","shell.execute_reply.started":"2024-04-18T14:56:09.895862Z","shell.execute_reply":"2024-04-18T14:56:09.909755Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:09.911712Z","iopub.execute_input":"2024-04-18T14:56:09.912069Z","iopub.status.idle":"2024-04-18T14:56:09.932356Z","shell.execute_reply.started":"2024-04-18T14:56:09.912030Z","shell.execute_reply":"2024-04-18T14:56:09.931313Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"features =\"image_data\"","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:09.933495Z","iopub.execute_input":"2024-04-18T14:56:09.933807Z","iopub.status.idle":"2024-04-18T14:56:09.938121Z","shell.execute_reply.started":"2024-04-18T14:56:09.933777Z","shell.execute_reply":"2024-04-18T14:56:09.937189Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\nimport tensorflow as tf\nimport numpy as np\nNUM_EPOCHS = 1\nSHUFFLE_BUFFER = 100\ndef create_tf_dataset_for_client_fn(client_id):\n    client_data = dataframe[dataframe[client_id_colname] == client_id]\n    client_data_dict = OrderedDict()\n    client_data_dict[\"image_data\"] = np.array(client_data['image_data'].values.tolist(), dtype=\"float32\")\n    client_data_dict[\"skin_disease\"] = np.array(client_data['skin_disease'].values.tolist(), dtype=\"int32\")\n\n    dataset = tf.data.Dataset.from_tensor_slices(client_data_dict)\n    dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(1).repeat(NUM_EPOCHS)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:09.939220Z","iopub.execute_input":"2024-04-18T14:56:09.939519Z","iopub.status.idle":"2024-04-18T14:56:09.949137Z","shell.execute_reply.started":"2024-04-18T14:56:09.939495Z","shell.execute_reply":"2024-04-18T14:56:09.948255Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import tensorflow_federated as tff\ndataframe = train_df\ntrain_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n    client_ids=train_client_ids,\n    serializable_dataset_fn=create_tf_dataset_for_client_fn)\n\ndataframe = test_df\ntest_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n    client_ids=test_client_ids,\n    serializable_dataset_fn=create_tf_dataset_for_client_fn)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:09.950334Z","iopub.execute_input":"2024-04-18T14:56:09.951786Z","iopub.status.idle":"2024-04-18T14:56:11.321888Z","shell.execute_reply.started":"2024-04-18T14:56:09.951748Z","shell.execute_reply":"2024-04-18T14:56:11.320899Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_data.element_type_structure","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:11.323158Z","iopub.execute_input":"2024-04-18T14:56:11.324726Z","iopub.status.idle":"2024-04-18T14:56:11.333612Z","shell.execute_reply.started":"2024-04-18T14:56:11.324696Z","shell.execute_reply":"2024-04-18T14:56:11.332793Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"OrderedDict([('image_data',\n              TensorSpec(shape=(None, 48, 64), dtype=tf.float32, name=None)),\n             ('skin_disease',\n              TensorSpec(shape=(None,), dtype=tf.int32, name=None))])"},"metadata":{}}]},{"cell_type":"code","source":"import collections\nNUM_EPOCHS = 1\nBATCH_SIZE = 10\nSHUFFLE_BUFFER = 100\nPREFETCH_BUFFER = 10\ndef preprocess(dataset):\n    def batch_format_fn(element):\n        return collections.OrderedDict(x=tf.reshape(element['image_data'], [-1,32,32,3]),\n                                       y=tf.reshape(element['skin_disease'], [-1, 1]))\n    return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(\n      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:11.335018Z","iopub.execute_input":"2024-04-18T14:56:11.335724Z","iopub.status.idle":"2024-04-18T14:56:11.351899Z","shell.execute_reply.started":"2024-04-18T14:56:11.335673Z","shell.execute_reply":"2024-04-18T14:56:11.351022Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef make_federated_data(client_data, client_ids):\n    return [preprocess(client_data.create_tf_dataset_for_client(x)) for x in tqdm(client_ids)]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:11.352949Z","iopub.execute_input":"2024-04-18T14:56:11.353213Z","iopub.status.idle":"2024-04-18T14:56:11.362046Z","shell.execute_reply.started":"2024-04-18T14:56:11.353190Z","shell.execute_reply":"2024-04-18T14:56:11.361233Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"NUM_CLIENTS = len(np.unique(train_df[client_id_colname]))\n\nsample_clients = train_data.client_ids[0:NUM_CLIENTS]\n\nfederated_train_data = make_federated_data(train_data, sample_clients)\n\nprint('Number of client datasets: {l}'.format(l=len(federated_train_data)))\nprint('First dataset: {d}'.format(d=federated_train_data[0]))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:11.363073Z","iopub.execute_input":"2024-04-18T14:56:11.363341Z","iopub.status.idle":"2024-04-18T14:56:11.581560Z","shell.execute_reply.started":"2024-04-18T14:56:11.363294Z","shell.execute_reply":"2024-04-18T14:56:11.580592Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 8/8 [00:00<00:00, 41.46it/s]","output_type":"stream"},{"name":"stdout","text":"Number of client datasets: 8\nFirst dataset: <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\ndef create_keras_model(input_shape=(32, 32, 3), num_classes=7):\n    base_model = tf.keras.applications.VGG19(include_top=False, input_shape=input_shape,weights='imagenet')\n\n    inputs = tf.keras.Input(shape=input_shape)\n    x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n    x = base_model(x, training=True)  # All layers are trainable\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n\n    model = tf.keras.Model(inputs, outputs)\n    return model\n\n\nmodel = create_keras_model()\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:11.585389Z","iopub.execute_input":"2024-04-18T14:56:11.585696Z","iopub.status.idle":"2024-04-18T14:56:12.742568Z","shell.execute_reply.started":"2024-04-18T14:56:11.585671Z","shell.execute_reply":"2024-04-18T14:56:12.741637Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80134624/80134624 [==============================] - 0s 0us/step\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n                                                                 \n tf.math.truediv (TFOpLambd  (None, 32, 32, 3)         0         \n a)                                                              \n                                                                 \n tf.math.subtract (TFOpLamb  (None, 32, 32, 3)         0         \n da)                                                             \n                                                                 \n vgg19 (Functional)          (None, 1, 1, 512)         20024384  \n                                                                 \n global_average_pooling2d (  (None, 512)               0         \n GlobalAveragePooling2D)                                         \n                                                                 \n dense (Dense)               (None, 7)                 3591      \n                                                                 \n=================================================================\nTotal params: 20027975 (76.40 MB)\nTrainable params: 20027975 (76.40 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"example_dataset = train_data.create_tf_dataset_for_client(train_data.client_ids[0])\n\nexample_element = next(iter(example_dataset))\n\nexample_element['skin_disease'].numpy()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:12.743899Z","iopub.execute_input":"2024-04-18T14:56:12.744271Z","iopub.status.idle":"2024-04-18T14:56:12.767917Z","shell.execute_reply.started":"2024-04-18T14:56:12.744229Z","shell.execute_reply":"2024-04-18T14:56:12.766942Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([2], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"preprocessed_example_dataset = preprocess(example_dataset)\n\nsample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n                                     next(iter(preprocessed_example_dataset)))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:12.769047Z","iopub.execute_input":"2024-04-18T14:56:12.769371Z","iopub.status.idle":"2024-04-18T14:56:12.802260Z","shell.execute_reply.started":"2024-04-18T14:56:12.769344Z","shell.execute_reply":"2024-04-18T14:56:12.801500Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"preprocessed_example_dataset.element_spec","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:12.803323Z","iopub.execute_input":"2024-04-18T14:56:12.803603Z","iopub.status.idle":"2024-04-18T14:56:12.809171Z","shell.execute_reply.started":"2024-04-18T14:56:12.803580Z","shell.execute_reply":"2024-04-18T14:56:12.808350Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"OrderedDict([('x',\n              TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None)),\n             ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])"},"metadata":{}}]},{"cell_type":"code","source":"from keras.metrics import Recall, Precision\n\ndef model_fn():\n    keras_model = create_keras_model()\n    return tff.learning.models.from_keras_model(\n        keras_model,\n        input_spec=preprocessed_example_dataset.element_spec,\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:12.810293Z","iopub.execute_input":"2024-04-18T14:56:12.810594Z","iopub.status.idle":"2024-04-18T14:56:12.818712Z","shell.execute_reply.started":"2024-04-18T14:56:12.810570Z","shell.execute_reply":"2024-04-18T14:56:12.817860Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"iterative_process = tff.learning.algorithms.build_weighted_fed_prox(\n    model_fn,\n    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.001),\n    proximal_strength=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:12.819806Z","iopub.execute_input":"2024-04-18T14:56:12.820379Z","iopub.status.idle":"2024-04-18T14:56:24.211114Z","shell.execute_reply.started":"2024-04-18T14:56:12.820347Z","shell.execute_reply":"2024-04-18T14:56:24.210330Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"str(iterative_process.initialize.type_signature)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:24.212417Z","iopub.execute_input":"2024-04-18T14:56:24.212776Z","iopub.status.idle":"2024-04-18T14:56:24.219699Z","shell.execute_reply.started":"2024-04-18T14:56:24.212731Z","shell.execute_reply":"2024-04-18T14:56:24.218776Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'( -> <global_model_weights=<trainable=<float32[3,3,3,64],float32[64],float32[3,3,64,64],float32[64],float32[3,3,64,128],float32[128],float32[3,3,128,128],float32[128],float32[3,3,128,256],float32[256],float32[3,3,256,256],float32[256],float32[3,3,256,256],float32[256],float32[3,3,256,256],float32[256],float32[3,3,256,512],float32[512],float32[3,3,512,512],float32[512],float32[3,3,512,512],float32[512],float32[3,3,512,512],float32[512],float32[3,3,512,512],float32[512],float32[3,3,512,512],float32[512],float32[3,3,512,512],float32[512],float32[3,3,512,512],float32[512],float32[512,7],float32[7]>,non_trainable=<>>,distributor=<>,client_work=<>,aggregator=<value_sum_process=<>,weight_sum_process=<>>,finalizer=<int64,float32[3,3,3,64],float32[64],float32[3,3,64,64],float32[64],float32[3,3,64,128],float32[128],float32[3,3,128,128],float32[128],float32[3,3,128,256],float32[256],float32[3,3,256,256],float32[256],float32[3,3,256,256],float32[256],float32[3,3,256,256],float32[256],float32[3,3,256,512],float32[512],float32[3,3,512,512],float32[512],float32[3,3,512,512],float32[512],float32[3,3,512,512],float32[512],float32[3,3,512,512],float32[512],float32[3,3,512,512],float32[512],float32[3,3,512,512],float32[512],float32[3,3,512,512],float32[512],float32[512,7],float32[7]>>@SERVER)'"},"metadata":{}}]},{"cell_type":"code","source":"state = iterative_process.initialize()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:24.220863Z","iopub.execute_input":"2024-04-18T14:56:24.221127Z","iopub.status.idle":"2024-04-18T14:56:27.848041Z","shell.execute_reply.started":"2024-04-18T14:56:24.221105Z","shell.execute_reply":"2024-04-18T14:56:27.847243Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1713452186.722306     232 session_provider.cc:108] Found devices: [/physical_device:CPU:0]\nI0000 00:00:1713452186.722344     232 session_provider.cc:124] Skipping device: [/physical_device:CPU:0]\nI0000 00:00:1713452186.722355     232 session_provider.cc:127] Found:\n\t0 GPUs\n\t0 TPUS\nin total\n","output_type":"stream"}]},{"cell_type":"code","source":"NUM_ROUNDS = 10\ntrain_state=state\nfor round_num in range(0, NUM_ROUNDS):\n  result = iterative_process.next(train_state, federated_train_data)\n  train_state = result.state\n  train_metrics = result.metrics\n  print('round {:2d}, metrics={}'.format(round_num, train_metrics))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:27.849091Z","iopub.execute_input":"2024-04-18T14:56:27.849353Z","iopub.status.idle":"2024-04-18T15:12:10.017209Z","shell.execute_reply.started":"2024-04-18T14:56:27.849329Z","shell.execute_reply":"2024-04-18T15:12:10.016319Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"round  0, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.60401005), ('loss', 4.781272), ('num_examples', 1596), ('num_batches', 164)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\nround  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.65037596), ('loss', 5.635274), ('num_examples', 1596), ('num_batches', 164)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\nround  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.65037596), ('loss', 5.635275), ('num_examples', 1596), ('num_batches', 164)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\nround  3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.65037596), ('loss', 5.6352735), ('num_examples', 1596), ('num_batches', 164)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\nround  4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.65037596), ('loss', 5.635274), ('num_examples', 1596), ('num_batches', 164)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\nround  5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.65037596), ('loss', 5.635275), ('num_examples', 1596), ('num_batches', 164)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\nround  6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.65037596), ('loss', 5.635275), ('num_examples', 1596), ('num_batches', 164)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\nround  7, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.65037596), ('loss', 5.635275), ('num_examples', 1596), ('num_batches', 164)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\nround  8, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.65037596), ('loss', 5.6352735), ('num_examples', 1596), ('num_batches', 164)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\nround  9, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.65037596), ('loss', 5.635274), ('num_examples', 1596), ('num_batches', 164)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluation_process = tff.learning.algorithms.build_fed_eval(model_fn)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:12:10.018513Z","iopub.execute_input":"2024-04-18T15:12:10.018874Z","iopub.status.idle":"2024-04-18T15:12:15.767202Z","shell.execute_reply.started":"2024-04-18T15:12:10.018840Z","shell.execute_reply":"2024-04-18T15:12:15.766386Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"evaluation_state = evaluation_process.initialize()\nmodel_weights = iterative_process.get_model_weights(train_state)\nevaluation_state = evaluation_process.set_model_weights(evaluation_state, model_weights)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:12:15.768326Z","iopub.execute_input":"2024-04-18T15:12:15.768674Z","iopub.status.idle":"2024-04-18T15:12:28.734901Z","shell.execute_reply.started":"2024-04-18T15:12:15.768643Z","shell.execute_reply":"2024-04-18T15:12:28.734074Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"federated_test_data = make_federated_data(test_data, test_client_ids)\n\nlen(federated_test_data), federated_test_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:12:28.736099Z","iopub.execute_input":"2024-04-18T15:12:28.736356Z","iopub.status.idle":"2024-04-18T15:12:28.783487Z","shell.execute_reply.started":"2024-04-18T15:12:28.736332Z","shell.execute_reply":"2024-04-18T15:12:28.782711Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"100%|██████████| 2/2 [00:00<00:00, 52.55it/s]\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(2,\n <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>)"},"metadata":{}}]},{"cell_type":"code","source":"evaluation_output = evaluation_process.next(evaluation_state, federated_test_data)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:12:28.784420Z","iopub.execute_input":"2024-04-18T15:12:28.784710Z","iopub.status.idle":"2024-04-18T15:12:35.767945Z","shell.execute_reply.started":"2024-04-18T15:12:28.784686Z","shell.execute_reply":"2024-04-18T15:12:35.767128Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"str(evaluation_output.metrics)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:12:35.768997Z","iopub.execute_input":"2024-04-18T15:12:35.769284Z","iopub.status.idle":"2024-04-18T15:12:35.775185Z","shell.execute_reply.started":"2024-04-18T15:12:35.769259Z","shell.execute_reply":"2024-04-18T15:12:35.774419Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"\"OrderedDict([('distributor', ()), ('client_work', OrderedDict([('eval', OrderedDict([('current_round_metrics', OrderedDict([('sparse_categorical_accuracy', 0.69287467), ('loss', 4.9502754), ('num_examples', 407), ('num_batches', 41)])), ('total_rounds_metrics', OrderedDict([('sparse_categorical_accuracy', 0.69287467), ('loss', 4.9502754), ('num_examples', 407), ('num_batches', 41)]))]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\""},"metadata":{}}]}]}