{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T16:59:53.413200Z","iopub.status.busy":"2024-04-06T16:59:53.412864Z","iopub.status.idle":"2024-04-06T17:02:11.921507Z","shell.execute_reply":"2024-04-06T17:02:11.920395Z","shell.execute_reply.started":"2024-04-06T16:59:53.413172Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow_federated\n","  Downloading tensorflow_federated-0.75.0-py3-none-manylinux_2_31_x86_64.whl.metadata (4.0 kB)\n","Requirement already satisfied: absl-py==1.*,>=1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_federated) (1.4.0)\n","Requirement already satisfied: attrs~=23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow_federated) (23.2.0)\n","Collecting cachetools~=5.3 (from tensorflow_federated)\n","  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n","Requirement already satisfied: dm-tree==0.1.8 in /opt/conda/lib/python3.10/site-packages (from tensorflow_federated) (0.1.8)\n","Collecting dp-accounting==0.4.3 (from tensorflow_federated)\n","  Downloading dp_accounting-0.4.3-py3-none-any.whl.metadata (1.8 kB)\n","Collecting farmhashpy==0.4.0 (from tensorflow_federated)\n","  Downloading farmhashpy-0.4.0.tar.gz (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting google-vizier==0.1.11 (from tensorflow_federated)\n","  Downloading google_vizier-0.1.11-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: grpcio~=1.46 in /opt/conda/lib/python3.10/site-packages (from tensorflow_federated) (1.51.1)\n","Collecting jaxlib==0.4.14 (from tensorflow_federated)\n","  Downloading jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.0 kB)\n","Collecting jax==0.4.14 (from tensorflow_federated)\n","  Downloading jax-0.4.14.tar.gz (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: numpy~=1.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow_federated) (1.26.4)\n","Collecting portpicker~=1.6 (from tensorflow_federated)\n","  Downloading portpicker-1.6.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting scipy~=1.9.3 (from tensorflow_federated)\n","  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version~=2.6 (from tensorflow_federated)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting tensorflow-compression==2.14.*,>=2.14.0 (from tensorflow_federated)\n","  Downloading tensorflow_compression-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Collecting tensorflow-model-optimization==0.7.5 (from tensorflow_federated)\n","  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n","Collecting tensorflow-privacy==0.9.0 (from tensorflow_federated)\n","  Downloading tensorflow_privacy-0.9.0-py3-none-any.whl.metadata (763 bytes)\n","Collecting tensorflow==2.14.*,>=2.14.0 (from tensorflow_federated)\n","  Downloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n","Requirement already satisfied: tqdm~=4.64 in /opt/conda/lib/python3.10/site-packages (from tensorflow_federated) (4.66.1)\n","Collecting typing-extensions==4.5.*,>=4.5.0 (from tensorflow_federated)\n","  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n","Collecting googleapis-common-protos==1.61.0 (from tensorflow_federated)\n","  Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: mpmath~=1.2 in /opt/conda/lib/python3.10/site-packages (from dp-accounting==0.4.3->tensorflow_federated) (1.3.0)\n","Collecting attrs~=23.1 (from tensorflow_federated)\n","  Downloading attrs-23.1.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: protobuf>=3.6 in /opt/conda/lib/python3.10/site-packages (from google-vizier==0.1.11->tensorflow_federated) (3.20.3)\n","Collecting grpcio-tools>=1.35.0 (from google-vizier==0.1.11->tensorflow_federated)\n","  Downloading grpcio_tools-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n","Collecting sqlalchemy<=1.4.20,>=1.4 (from google-vizier==0.1.11->tensorflow_federated)\n","  Downloading SQLAlchemy-1.4.20.tar.gz (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.14->tensorflow_federated) (0.2.0)\n","Requirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax==0.4.14->tensorflow_federated) (3.3.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.10.0)\n","Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (16.0.6)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (21.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (69.0.3)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.4.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.35.0)\n","Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n","  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n","Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n","  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n","  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n","INFO: pip is looking at multiple versions of tensorflow-compression to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow-compression==2.14.*,>=2.14.0 (from tensorflow_federated)\n","  Downloading tensorflow_compression-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: tensorflow-probability~=0.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow-compression==2.14.*,>=2.14.0->tensorflow_federated) (0.23.0)\n","Collecting packaging (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n","  Downloading packaging-22.0-py3-none-any.whl.metadata (3.1 kB)\n","Requirement already satisfied: scikit-learn==1.*,>=1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-privacy==0.9.0->tensorflow_federated) (1.2.2)\n","Collecting tensorflow-probability~=0.15 (from tensorflow-compression==2.14.*,>=2.14.0->tensorflow_federated)\n","  Downloading tensorflow_probability-0.22.1-py2.py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow_federated) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow_federated) (3.2.0)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker~=1.6->tensorflow_federated) (5.9.3)\n","Collecting numpy~=1.25 (from tensorflow_federated)\n","  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.42.0)\n","Collecting protobuf>=3.6 (from google-vizier==0.1.11->tensorflow_federated)\n","  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Collecting grpcio~=1.46 (from tensorflow_federated)\n","  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<=1.4.20,>=1.4->google-vizier==0.1.11->tensorflow_federated) (3.0.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.26.1)\n","Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n","  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.0.1)\n","Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability~=0.15->tensorflow-compression==2.14.*,>=2.14.0->tensorflow_federated) (5.1.1)\n","Requirement already satisfied: cloudpickle>=1.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability~=0.15->tensorflow-compression==2.14.*,>=2.14.0->tensorflow_federated) (2.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.2.2)\n","Downloading tensorflow_federated-0.75.0-py3-none-manylinux_2_31_x86_64.whl (70.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading dp_accounting-0.4.3-py3-none-any.whl (104 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading google_vizier-0.1.11-py3-none-any.whl (721 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.6/721.6 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading attrs-23.1.0-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl (230 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl (73.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading tensorflow_compression-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (257 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.7/257.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_privacy-0.9.0-py3-none-any.whl (323 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n","Downloading portpicker-1.6.0-py3-none-any.whl (16 kB)\n","Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading grpcio_tools-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-22.0-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_probability-0.22.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n","Building wheels for collected packages: farmhashpy, jax, sqlalchemy\n","  Building wheel for farmhashpy (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for farmhashpy: filename=farmhashpy-0.4.0-cp310-cp310-linux_x86_64.whl size=12965 sha256=74c47fb52f9f71130d6ae6407a7985a63b7271ebbafea028833608745a036031\n","  Stored in directory: /root/.cache/pip/wheels/14/0e/36/b61b3f47ae366b7d5dd2b746326d17234269dbc745ad554857\n","  Building wheel for jax (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for jax: filename=jax-0.4.14-py3-none-any.whl size=1535361 sha256=1f3ce0b90749c34c52b289eb710575d615c4127dfac4f7eb56ebc319e5a43060\n","  Stored in directory: /root/.cache/pip/wheels/85/52/e7/dfa571c9f9b879e3facaa1584f52be04c4c3d1e14054ef40ab\n","  Building wheel for sqlalchemy (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for sqlalchemy: filename=SQLAlchemy-1.4.20-cp310-cp310-linux_x86_64.whl size=1490638 sha256=50cba9984907f1afc346b130b5689c346c99c01ae683a084de5e663da3553a60\n","  Stored in directory: /root/.cache/pip/wheels/c4/42/20/a958989c470cc1a6fe1d1279b0193f0e508161327fc3d951d9\n","Successfully built farmhashpy jax sqlalchemy\n","Installing collected packages: typing-extensions, tensorflow-estimator, sqlalchemy, semantic-version, protobuf, portpicker, packaging, numpy, keras, grpcio, farmhashpy, cachetools, attrs, tensorflow-probability, tensorflow-model-optimization, scipy, grpcio-tools, googleapis-common-protos, jaxlib, jax, google-vizier, google-auth-oauthlib, dp-accounting, tensorboard, tensorflow, tensorflow-privacy, tensorflow-compression, tensorflow_federated\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.9.0\n","    Uninstalling typing_extensions-4.9.0:\n","      Successfully uninstalled typing_extensions-4.9.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.15.0\n","    Uninstalling tensorflow-estimator-2.15.0:\n","      Successfully uninstalled tensorflow-estimator-2.15.0\n","  Attempting uninstall: sqlalchemy\n","    Found existing installation: SQLAlchemy 2.0.25\n","    Uninstalling SQLAlchemy-2.0.25:\n","      Successfully uninstalled SQLAlchemy-2.0.25\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.0.5\n","    Uninstalling keras-3.0.5:\n","      Successfully uninstalled keras-3.0.5\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.51.1\n","    Uninstalling grpcio-1.51.1:\n","      Successfully uninstalled grpcio-1.51.1\n","  Attempting uninstall: cachetools\n","    Found existing installation: cachetools 4.2.4\n","    Uninstalling cachetools-4.2.4:\n","      Successfully uninstalled cachetools-4.2.4\n","  Attempting uninstall: attrs\n","    Found existing installation: attrs 23.2.0\n","    Uninstalling attrs-23.2.0:\n","      Successfully uninstalled attrs-23.2.0\n","  Attempting uninstall: tensorflow-probability\n","    Found existing installation: tensorflow-probability 0.23.0\n","    Uninstalling tensorflow-probability-0.23.0:\n","      Successfully uninstalled tensorflow-probability-0.23.0\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.11.4\n","    Uninstalling scipy-1.11.4:\n","      Successfully uninstalled scipy-1.11.4\n","  Attempting uninstall: googleapis-common-protos\n","    Found existing installation: googleapis-common-protos 1.62.0\n","    Uninstalling googleapis-common-protos-1.62.0:\n","      Successfully uninstalled googleapis-common-protos-1.62.0\n","  Attempting uninstall: jaxlib\n","    Found existing installation: jaxlib 0.4.23.dev20240116\n","    Uninstalling jaxlib-0.4.23.dev20240116:\n","      Successfully uninstalled jaxlib-0.4.23.dev20240116\n","  Attempting uninstall: jax\n","    Found existing installation: jax 0.4.23\n","    Uninstalling jax-0.4.23:\n","      Successfully uninstalled jax-0.4.23\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.2.0\n","    Uninstalling google-auth-oauthlib-1.2.0:\n","      Successfully uninstalled google-auth-oauthlib-1.2.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.1\n","    Uninstalling tensorboard-2.15.1:\n","      Successfully uninstalled tensorboard-2.15.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cubinlinker, which is not installed.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 23.8.0 requires ptxcompiler, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","keras-cv 0.8.2 requires keras-core, which is not installed.\n","keras-nlp 0.8.2 requires keras-core, which is not installed.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","albumentations 1.4.0 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.25.2 which is incompatible.\n","apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\n","chex 0.1.85 requires jax>=0.4.16, but you have jax 0.4.14 which is incompatible.\n","cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\n","cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\n","dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\n","dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\n","dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","distributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\n","fastapi 0.108.0 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n","featuretools 1.30.0 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\n","flax 0.8.2 requires jax>=0.4.19, but you have jax 0.4.14 which is incompatible.\n","gcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2024.3.0 which is incompatible.\n","google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\n","google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 22.0 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.3 which is incompatible.\n","google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n","google-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.3 which is incompatible.\n","ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.20 which is incompatible.\n","jupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","kaggle-environments 1.14.3 requires scipy>=1.11.2, but you have scipy 1.9.3 which is incompatible.\n","kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n","kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n","kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.3 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","osmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n","pydantic 2.5.3 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n","pydantic-core 2.14.6 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n","pylibraft 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\n","pytoolconfig 1.3.1 requires packaging>=23.2, but you have packaging 22.0 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\n","rmm 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\n","spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","tensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.14.1 which is incompatible.\n","tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\n","tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.14.1 which is incompatible.\n","tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\n","tensorstore 0.1.56 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.14.1 which is incompatible.\n","typeguard 4.1.5 requires typing-extensions>=4.7.0; python_version < \"3.12\", but you have typing-extensions 4.5.0 which is incompatible.\n","woodwork 0.29.0 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed attrs-23.1.0 cachetools-5.3.2 dp-accounting-0.4.3 farmhashpy-0.4.0 google-auth-oauthlib-1.0.0 google-vizier-0.1.11 googleapis-common-protos-1.61.0 grpcio-1.60.0 grpcio-tools-1.62.1 jax-0.4.14 jaxlib-0.4.14 keras-2.14.0 numpy-1.25.2 packaging-22.0 portpicker-1.6.0 protobuf-4.21.12 scipy-1.12.0 semantic-version-2.10.0 sqlalchemy-1.4.20 tensorboard-2.14.1 tensorflow-2.14.1 tensorflow-compression-2.14.0 tensorflow-estimator-2.14.0 tensorflow-model-optimization-0.7.5 tensorflow-privacy-0.9.0 tensorflow-probability-0.22.1 tensorflow_federated-0.75.0 typing-extensions-4.5.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install tensorflow_federated"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:04:41.407661Z","iopub.status.busy":"2024-04-06T17:04:41.407270Z","iopub.status.idle":"2024-04-06T17:04:47.825265Z","shell.execute_reply":"2024-04-06T17:04:47.824433Z","shell.execute_reply.started":"2024-04-06T17:04:41.407632Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","2024-04-06 17:04:43.500368: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-06 17:04:43.500437: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-06 17:04:43.500492: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import os\n","import cv2\n","import random\n","import itertools\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.utils import to_categorical, plot_model\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import layers, regularizers, optimizers, callbacks\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:05:26.938006Z","iopub.status.busy":"2024-04-06T17:05:26.936978Z","iopub.status.idle":"2024-04-06T17:08:24.980579Z","shell.execute_reply":"2024-04-06T17:08:24.979601Z","shell.execute_reply.started":"2024-04-06T17:05:26.937972Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data from: /kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1\n","Loading data from: /kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2\n","Structure of the merged HAM dataset:\n","                                          image_data skin_disease\n","0  [[0.68235296, 0.6666667, 0.6784314, 0.6509804,...           nv\n","1  [[0.5568628, 0.5803922, 0.5764706, 0.58431375,...           nv\n","2  [[0.6666667, 0.6431373, 0.67058825, 0.7058824,...           nv\n","3  [[0.54509807, 0.53333336, 0.5254902, 0.4862745...          bkl\n","4  [[0.5764706, 0.5686275, 0.5647059, 0.6039216, ...          bkl\n","                                          image_data  skin_disease\n","0  [[0.68235296, 0.6666667, 0.6784314, 0.6509804,...             5\n","1  [[0.5568628, 0.5803922, 0.5764706, 0.58431375,...             5\n","2  [[0.6666667, 0.6431373, 0.67058825, 0.7058824,...             5\n","3  [[0.54509807, 0.53333336, 0.5254902, 0.4862745...             2\n","4  [[0.5764706, 0.5686275, 0.5647059, 0.6039216, ...             2\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Check if GPU is available\n","device = '/GPU:0' if tf.config.experimental.list_physical_devices('GPU') else '/CPU:0'\n","\n","# Define paths\n","HAM_PATH_PART1 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1\"\n","HAM_PATH_PART2 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2\"\n","METADATA_PATH = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\"\n","\n","def load_data_ham(path, metadata_path):\n","    print(\"Loading data from:\", path)\n","    data = []\n","    metadata = pd.read_csv(metadata_path)\n","    for img_file in os.listdir(path):\n","        img_id = img_file.split('.')[0]\n","        metadata_row = metadata[metadata['image_id'] == img_id]\n","        if not metadata_row.empty:\n","            lesion_type = metadata_row.iloc[0]['dx']\n","            img_path = os.path.join(path, img_file)\n","            img_resize = process_image(img_path)\n","            data.append([img_resize, lesion_type])\n","    return data\n","\n","def process_image(img_path, target_size=(64, 48)):\n","    img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","\n","    # Resize image to target size\n","    img_resize = cv2.resize(img_array, target_size)\n","\n","    # Normalize pixel values to [0, 1]\n","    img_normalize = img_resize.astype(np.float32) / 255.0\n","\n","    return img_normalize\n","\n","# Load data for HAM dataset\n","with tf.device(device):\n","    ham_data_part1 = load_data_ham(HAM_PATH_PART1, METADATA_PATH)\n","    ham_data_part2 = load_data_ham(HAM_PATH_PART2, METADATA_PATH)\n","\n","# Concatenate HAM datasets into a single list\n","all_ham_data = ham_data_part1 + ham_data_part2\n","\n","# Convert the list of lists to a DataFrame\n","column_names = ['image_data', 'skin_disease']\n","ham_df = pd.DataFrame(all_ham_data, columns=column_names)\n","\n","# Print the structure of the merged HAM dataset\n","print(\"Structure of the merged HAM dataset:\")\n","print(ham_df.head())\n","\n","# Initialize LabelEncoder\n","label_encoder = LabelEncoder()\n","\n","# Fit and transform the 'skin_disease' column\n","ham_df['skin_disease'] = label_encoder.fit_transform(ham_df['skin_disease'])\n","\n","# Print the encoded DataFrame\n","print(ham_df.head())\n","df=pd.DataFrame(ham_df)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:09:58.956353Z","iopub.status.busy":"2024-04-06T17:09:58.956010Z","iopub.status.idle":"2024-04-06T17:09:58.982628Z","shell.execute_reply":"2024-04-06T17:09:58.981794Z","shell.execute_reply.started":"2024-04-06T17:09:58.956328Z"},"trusted":true},"outputs":[],"source":["import random\n","\n","num_client = 10\n","\n","df[\"client\"] = [\"client_{}\".format(random.randint(1, num_client)) for _ in range(df.shape[0])]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:10:00.502201Z","iopub.status.busy":"2024-04-06T17:10:00.501578Z","iopub.status.idle":"2024-04-06T17:10:00.513442Z","shell.execute_reply":"2024-04-06T17:10:00.512480Z","shell.execute_reply.started":"2024-04-06T17:10:00.502158Z"},"trusted":true},"outputs":[],"source":["client_id_colname = 'client'\n","\n","client_ids = df[client_id_colname].unique()\n","\n","train_client_ids = pd.DataFrame(client_ids).sample(frac=0.8).values.ravel().tolist()\n","test_client_ids = [x for x in client_ids if x not in train_client_ids]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:10:16.524180Z","iopub.status.busy":"2024-04-06T17:10:16.523814Z","iopub.status.idle":"2024-04-06T17:10:16.530101Z","shell.execute_reply":"2024-04-06T17:10:16.529080Z","shell.execute_reply.started":"2024-04-06T17:10:16.524151Z"},"trusted":true},"outputs":[],"source":["import nest_asyncio\n","nest_asyncio.apply()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:10:23.551305Z","iopub.status.busy":"2024-04-06T17:10:23.550935Z","iopub.status.idle":"2024-04-06T17:10:23.562620Z","shell.execute_reply":"2024-04-06T17:10:23.561794Z","shell.execute_reply.started":"2024-04-06T17:10:23.551278Z"},"trusted":true},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:10:31.025240Z","iopub.status.busy":"2024-04-06T17:10:31.024891Z","iopub.status.idle":"2024-04-06T17:10:31.032167Z","shell.execute_reply":"2024-04-06T17:10:31.031266Z","shell.execute_reply.started":"2024-04-06T17:10:31.025214Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['client_5',\n"," 'client_10',\n"," 'client_6',\n"," 'client_9',\n"," 'client_3',\n"," 'client_4',\n"," 'client_7',\n"," 'client_1']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train_client_ids"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:10:39.710624Z","iopub.status.busy":"2024-04-06T17:10:39.709720Z","iopub.status.idle":"2024-04-06T17:10:39.720053Z","shell.execute_reply":"2024-04-06T17:10:39.719114Z","shell.execute_reply.started":"2024-04-06T17:10:39.710592Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:10:47.569774Z","iopub.status.busy":"2024-04-06T17:10:47.569120Z","iopub.status.idle":"2024-04-06T17:10:47.573693Z","shell.execute_reply":"2024-04-06T17:10:47.572879Z","shell.execute_reply.started":"2024-04-06T17:10:47.569729Z"},"trusted":true},"outputs":[],"source":["features =\"image_data\""]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:10:55.733243Z","iopub.status.busy":"2024-04-06T17:10:55.732889Z","iopub.status.idle":"2024-04-06T17:10:55.740064Z","shell.execute_reply":"2024-04-06T17:10:55.739156Z","shell.execute_reply.started":"2024-04-06T17:10:55.733207Z"},"trusted":true},"outputs":[],"source":["from collections import OrderedDict\n","import tensorflow as tf\n","import numpy as np\n","\n","NUM_EPOCHS = 1\n","SHUFFLE_BUFFER = 100\n","\n","def create_tf_dataset_for_client_fn(client_id):\n","    client_data = dataframe[dataframe[client_id_colname] == client_id]\n","    client_data_dict = OrderedDict()\n","    client_data_dict[\"image_data\"] = np.array(client_data['image_data'].values.tolist(), dtype=\"float32\")\n","    client_data_dict[\"skin_disease\"] = np.array(client_data['skin_disease'].values.tolist(), dtype=\"int32\")\n","\n","    dataset = tf.data.Dataset.from_tensor_slices(client_data_dict)\n","    dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(1).repeat(NUM_EPOCHS)\n","    return dataset"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:11:06.369565Z","iopub.status.busy":"2024-04-06T17:11:06.369205Z","iopub.status.idle":"2024-04-06T17:11:07.637407Z","shell.execute_reply":"2024-04-06T17:11:07.636642Z","shell.execute_reply.started":"2024-04-06T17:11:06.369537Z"},"trusted":true},"outputs":[],"source":["import tensorflow_federated as tff"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:11:13.533170Z","iopub.status.busy":"2024-04-06T17:11:13.532788Z","iopub.status.idle":"2024-04-06T17:11:13.598545Z","shell.execute_reply":"2024-04-06T17:11:13.597492Z","shell.execute_reply.started":"2024-04-06T17:11:13.533138Z"},"trusted":true},"outputs":[],"source":["dataframe = train_df\n","train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n","    client_ids=train_client_ids,\n","    serializable_dataset_fn=create_tf_dataset_for_client_fn)\n","\n","dataframe = test_df\n","test_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n","    client_ids=test_client_ids,\n","    serializable_dataset_fn=create_tf_dataset_for_client_fn)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:11:19.807070Z","iopub.status.busy":"2024-04-06T17:11:19.806333Z","iopub.status.idle":"2024-04-06T17:11:19.813015Z","shell.execute_reply":"2024-04-06T17:11:19.812005Z","shell.execute_reply.started":"2024-04-06T17:11:19.807042Z"},"trusted":true},"outputs":[{"data":{"text/plain":["OrderedDict([('image_data',\n","              TensorSpec(shape=(None, 48, 64), dtype=tf.float32, name=None)),\n","             ('skin_disease',\n","              TensorSpec(shape=(None,), dtype=tf.int32, name=None))])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["train_data.element_type_structure"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:11:27.060972Z","iopub.status.busy":"2024-04-06T17:11:27.060629Z","iopub.status.idle":"2024-04-06T17:11:27.067548Z","shell.execute_reply":"2024-04-06T17:11:27.066618Z","shell.execute_reply.started":"2024-04-06T17:11:27.060946Z"},"trusted":true},"outputs":[],"source":["import collections\n","\n","NUM_EPOCHS = 1\n","BATCH_SIZE = 10\n","SHUFFLE_BUFFER = 100\n","PREFETCH_BUFFER = 10\n","\n","def preprocess(dataset):\n","    def batch_format_fn(element):\n","        return collections.OrderedDict(x=tf.reshape(element['image_data'], [-1,32,32,3]),\n","                                       y=tf.reshape(element['skin_disease'], [-1, 1]))\n","\n","    return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(\n","      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:11:42.005331Z","iopub.status.busy":"2024-04-06T17:11:42.004977Z","iopub.status.idle":"2024-04-06T17:11:42.010051Z","shell.execute_reply":"2024-04-06T17:11:42.009170Z","shell.execute_reply.started":"2024-04-06T17:11:42.005300Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","\n","def make_federated_data(client_data, client_ids):\n","    return [preprocess(client_data.create_tf_dataset_for_client(x)) for x in tqdm(client_ids)]"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:11:49.888631Z","iopub.status.busy":"2024-04-06T17:11:49.888268Z","iopub.status.idle":"2024-04-06T17:11:50.120077Z","shell.execute_reply":"2024-04-06T17:11:50.119170Z","shell.execute_reply.started":"2024-04-06T17:11:49.888603Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:00<00:00, 37.63it/s]"]},{"name":"stdout","output_type":"stream","text":["Number of client datasets: 8\n","First dataset: <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["NUM_CLIENTS = len(np.unique(train_df[client_id_colname]))\n","\n","sample_clients = train_data.client_ids[0:NUM_CLIENTS]\n","\n","federated_train_data = make_federated_data(train_data, sample_clients)\n","\n","print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n","print('First dataset: {d}'.format(d=federated_train_data[0]))"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:11:58.679113Z","iopub.status.busy":"2024-04-06T17:11:58.678766Z","iopub.status.idle":"2024-04-06T17:11:58.685792Z","shell.execute_reply":"2024-04-06T17:11:58.684812Z","shell.execute_reply.started":"2024-04-06T17:11:58.679086Z"},"trusted":true},"outputs":[],"source":["def create_keras_model(input_shape=(32, 32, 3), num_classes=7):\n","    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n","    base_model.trainable = False\n","\n","    inputs = tf.keras.Input(shape=input_shape)\n","    x = tf.keras.applications.resnet.preprocess_input(inputs)\n","    x = base_model(x, training=False)\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n","\n","    model = tf.keras.Model(inputs, outputs)\n","    return model"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:12:07.657997Z","iopub.status.busy":"2024-04-06T17:12:07.657568Z","iopub.status.idle":"2024-04-06T17:12:07.680427Z","shell.execute_reply":"2024-04-06T17:12:07.679500Z","shell.execute_reply.started":"2024-04-06T17:12:07.657969Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([1], dtype=int32)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["example_dataset = train_data.create_tf_dataset_for_client(train_data.client_ids[0])\n","\n","example_element = next(iter(example_dataset))\n","\n","example_element['skin_disease'].numpy()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:12:16.202016Z","iopub.status.busy":"2024-04-06T17:12:16.201654Z","iopub.status.idle":"2024-04-06T17:12:16.236493Z","shell.execute_reply":"2024-04-06T17:12:16.235572Z","shell.execute_reply.started":"2024-04-06T17:12:16.201989Z"},"trusted":true},"outputs":[],"source":["preprocessed_example_dataset = preprocess(example_dataset)\n","\n","sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n","                                     next(iter(preprocessed_example_dataset)))"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:12:24.463569Z","iopub.status.busy":"2024-04-06T17:12:24.463217Z","iopub.status.idle":"2024-04-06T17:12:24.469877Z","shell.execute_reply":"2024-04-06T17:12:24.468903Z","shell.execute_reply.started":"2024-04-06T17:12:24.463545Z"},"trusted":true},"outputs":[{"data":{"text/plain":["OrderedDict([('x',\n","              TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None)),\n","             ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["preprocessed_example_dataset.element_spec"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:12:31.573143Z","iopub.status.busy":"2024-04-06T17:12:31.572738Z","iopub.status.idle":"2024-04-06T17:12:31.578826Z","shell.execute_reply":"2024-04-06T17:12:31.577812Z","shell.execute_reply.started":"2024-04-06T17:12:31.573114Z"},"trusted":true},"outputs":[],"source":["from keras.metrics import Recall, Precision\n","\n","def model_fn():\n","    keras_model = create_keras_model()\n","    return tff.learning.models.from_keras_model(\n","        keras_model,\n","        input_spec=preprocessed_example_dataset.element_spec,\n","        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:12:39.715118Z","iopub.status.busy":"2024-04-06T17:12:39.714260Z","iopub.status.idle":"2024-04-06T17:13:18.671259Z","shell.execute_reply":"2024-04-06T17:13:18.670205Z","shell.execute_reply.started":"2024-04-06T17:12:39.715080Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 3s 0us/step\n"]}],"source":["iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n","    model_fn,\n","    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.001))"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:13:18.673259Z","iopub.status.busy":"2024-04-06T17:13:18.672942Z","iopub.status.idle":"2024-04-06T17:13:18.685166Z","shell.execute_reply":"2024-04-06T17:13:18.684100Z","shell.execute_reply.started":"2024-04-06T17:13:18.673227Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'( -> <global_model_weights=<trainable=<float32[2048,7],float32[7]>,non_trainable=<float32[7,7,3,64],float32[64],float32[64],float32[64],float32[64],float32[64],float32[1,1,64,64],float32[64],float32[64],float32[64],float32[64],float32[64],float32[3,3,64,64],float32[64],float32[64],float32[64],float32[64],float32[64],float32[1,1,64,256],float32[256],float32[1,1,64,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[1,1,256,64],float32[64],float32[64],float32[64],float32[64],float32[64],float32[3,3,64,64],float32[64],float32[64],float32[64],float32[64],float32[64],float32[1,1,64,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[1,1,256,64],float32[64],float32[64],float32[64],float32[64],float32[64],float32[3,3,64,64],float32[64],float32[64],float32[64],float32[64],float32[64],float32[1,1,64,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[1,1,256,128],float32[128],float32[128],float32[128],float32[128],float32[128],float32[3,3,128,128],float32[128],float32[128],float32[128],float32[128],float32[128],float32[1,1,256,512],float32[512],float32[1,1,128,512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[1,1,512,128],float32[128],float32[128],float32[128],float32[128],float32[128],float32[3,3,128,128],float32[128],float32[128],float32[128],float32[128],float32[128],float32[1,1,128,512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[1,1,512,128],float32[128],float32[128],float32[128],float32[128],float32[128],float32[3,3,128,128],float32[128],float32[128],float32[128],float32[128],float32[128],float32[1,1,128,512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[1,1,512,128],float32[128],float32[128],float32[128],float32[128],float32[128],float32[3,3,128,128],float32[128],float32[128],float32[128],float32[128],float32[128],float32[1,1,128,512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[1,1,512,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[3,3,256,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[1,1,512,1024],float32[1024],float32[1,1,256,1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1,1,1024,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[3,3,256,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[1,1,256,1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1,1,1024,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[3,3,256,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[1,1,256,1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1,1,1024,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[3,3,256,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[1,1,256,1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1,1,1024,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[3,3,256,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[1,1,256,1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1,1,1024,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[3,3,256,256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[1,1,256,1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1,1,1024,512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[3,3,512,512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[1,1,1024,2048],float32[2048],float32[1,1,512,2048],float32[2048],float32[2048],float32[2048],float32[2048],float32[2048],float32[2048],float32[2048],float32[2048],float32[2048],float32[1,1,2048,512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[3,3,512,512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[1,1,512,2048],float32[2048],float32[2048],float32[2048],float32[2048],float32[2048],float32[1,1,2048,512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[3,3,512,512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[1,1,512,2048],float32[2048],float32[2048],float32[2048],float32[2048],float32[2048]>>,distributor=<>,client_work=<>,aggregator=<value_sum_process=<>,weight_sum_process=<>>,finalizer=<learning_rate=float32>>@SERVER)'"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["str(iterative_process.initialize.type_signature)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:13:23.142061Z","iopub.status.busy":"2024-04-06T17:13:23.141365Z","iopub.status.idle":"2024-04-06T17:13:27.632079Z","shell.execute_reply":"2024-04-06T17:13:27.631095Z","shell.execute_reply.started":"2024-04-06T17:13:23.142010Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1712423606.895581     234 session_provider.cc:108] Found devices: [/physical_device:CPU:0]\n","I0000 00:00:1712423606.895635     234 session_provider.cc:124] Skipping device: [/physical_device:CPU:0]\n","I0000 00:00:1712423606.895638     234 session_provider.cc:127] Found:\n","\t0 GPUs\n","\t0 TPUS\n","in total\n"]}],"source":["state = iterative_process.initialize()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:13:34.769950Z","iopub.status.busy":"2024-04-06T17:13:34.769088Z","iopub.status.idle":"2024-04-06T17:21:08.845142Z","shell.execute_reply":"2024-04-06T17:21:08.844180Z","shell.execute_reply.started":"2024-04-06T17:13:34.769917Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["round  0, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.55289054), ('loss', 3.4457488), ('num_examples', 1626), ('num_batches', 166)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n","round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5436654), ('loss', 3.6372576), ('num_examples', 1626), ('num_batches', 166)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n","round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.50246), ('loss', 3.1170409), ('num_examples', 1626), ('num_batches', 166)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n","round  3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.52460027), ('loss', 2.834058), ('num_examples', 1626), ('num_batches', 166)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n","round  4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.53075033), ('loss', 3.3400419), ('num_examples', 1626), ('num_batches', 166)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n","round  5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5190652), ('loss', 3.6758337), ('num_examples', 1626), ('num_batches', 166)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n","round  6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5215252), ('loss', 3.609137), ('num_examples', 1626), ('num_batches', 166)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n","round  7, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.53075033), ('loss', 3.8243475), ('num_examples', 1626), ('num_batches', 166)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n","round  8, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.53628534), ('loss', 3.543095), ('num_examples', 1626), ('num_batches', 166)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n","round  9, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5455105), ('loss', 3.7586467), ('num_examples', 1626), ('num_batches', 166)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"]}],"source":["NUM_ROUNDS = 10\n","for round_num in range(0, NUM_ROUNDS):\n","  result = iterative_process.next(state, federated_train_data)\n","  train_state = result.state\n","  train_metrics = result.metrics\n","  print('round {:2d}, metrics={}'.format(round_num, train_metrics))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:26:39.113591Z","iopub.status.busy":"2024-04-06T17:26:39.113161Z","iopub.status.idle":"2024-04-06T17:27:10.426324Z","shell.execute_reply":"2024-04-06T17:27:10.425512Z","shell.execute_reply.started":"2024-04-06T17:26:39.113560Z"},"trusted":true},"outputs":[],"source":["evaluation_process = tff.learning.algorithms.build_fed_eval(model_fn)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:27:16.649689Z","iopub.status.busy":"2024-04-06T17:27:16.649329Z","iopub.status.idle":"2024-04-06T17:27:32.040897Z","shell.execute_reply":"2024-04-06T17:27:32.040096Z","shell.execute_reply.started":"2024-04-06T17:27:16.649660Z"},"trusted":true},"outputs":[],"source":["evaluation_state = evaluation_process.initialize()\n","model_weights = iterative_process.get_model_weights(train_state)\n","evaluation_state = evaluation_process.set_model_weights(evaluation_state, model_weights)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:27:34.946186Z","iopub.status.busy":"2024-04-06T17:27:34.945307Z","iopub.status.idle":"2024-04-06T17:27:34.994934Z","shell.execute_reply":"2024-04-06T17:27:34.993980Z","shell.execute_reply.started":"2024-04-06T17:27:34.946152Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [00:00<00:00, 50.89it/s]\n"]},{"data":{"text/plain":["(2,\n"," <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["federated_test_data = make_federated_data(test_data, test_client_ids)\n","\n","len(federated_test_data), federated_test_data[0]"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:27:49.374906Z","iopub.status.busy":"2024-04-06T17:27:49.374459Z","iopub.status.idle":"2024-04-06T17:28:00.692268Z","shell.execute_reply":"2024-04-06T17:28:00.691454Z","shell.execute_reply.started":"2024-04-06T17:27:49.374864Z"},"trusted":true},"outputs":[],"source":["evaluation_output = evaluation_process.next(evaluation_state, federated_test_data)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:28:00.694824Z","iopub.status.busy":"2024-04-06T17:28:00.694108Z","iopub.status.idle":"2024-04-06T17:28:00.701048Z","shell.execute_reply":"2024-04-06T17:28:00.700029Z","shell.execute_reply.started":"2024-04-06T17:28:00.694787Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"OrderedDict([('distributor', ()), ('client_work', OrderedDict([('eval', OrderedDict([('current_round_metrics', OrderedDict([('sparse_categorical_accuracy', 0.69496024), ('loss', 4.6836557), ('num_examples', 377), ('num_batches', 39)])), ('total_rounds_metrics', OrderedDict([('sparse_categorical_accuracy', 0.69496024), ('loss', 4.6836557), ('num_examples', 377), ('num_batches', 39)]))]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\""]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["str(evaluation_output.metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":54339,"sourceId":104884,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
